#Exercise 1 by Fuat Arslan
1. sqoop import \
	--options-file pass.txt \
	--table calllog
	--target-dir /user/training/problem1/output
	--fields-terminated-by '\t'

2. val rdd = sc.textFile("/user/training/problem1/output")
	val rddDrop = rdd.filter(line => line.contains("DROPPED")
	val rddFail = rdd.filter(line => line.contains("FAILED")
	val rddSucc = rdd.filter(line => line.contains("SUCCESS")

	rddDrop.saveAsTextFile("/user/training/problem2/output/status=DROPPED")
	rddFail.saveAsTextFile("/user/training/problem2/output/status=FAILED")
	rddSucc.saveAsTextFile("/user/training/problem2/output/status=SUCCESS")
3. CREATE EXTERNAL TABLE calllog (
  
  call_num STRING,
  start_time TIMESTAMP,
  end_time TIMESTAMP,
  from_phone_number STRING,
  to_phone_number STRING
  
  ) 
  PARTITIONED BY (status STRING)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '\t'
  LOCATION '/user/training/problem2/calllog'

4. MSCK REPAIR TABLE calllog
  
  SELECT * FROM calllog LIMIT 2;
  
  
  SELECT status, substr(avg(unix_timestamp(end_time)-unix_timestamp(start_time)), 1,5) as timediff 
  FROM calllog
  GROUP BY status

5. sqoop import
 --connect jdbc:mysql://localhost:3306/loudacre
 --username training --password training 
 --table accountdevice
 --target-dir /user/training/problem5/output/accountdevice
 --fields-terminated-by '\t' 


 sqoop import 
 --connect jdbc:mysql://localhost:3306/loudacre 
 --username training --password training 
 --table accounts
 --target-dir /user/training/problem5/output/accounts 
 --fields-terminated-by '\t'

6.
    val accounts = sc.textFile("/user/training/problem5/output/accounts")
	val account_dev = sc.textFile("/user/training/problem5/output/accountdevice")


val accounts1 = accounts.map(line => line.split('\t')).map(line =>( line(0),line))

val account_dev1 = account_dev.map(line => line.split('\t')).map(line =>( line(1),line))

val joinedAcc = accounts1.join(account_dev1)

val preSorted = joinedAcc.map(line =>(line._2._2(3), line._2._1(0)+"\t"+line._2._1(9)))

val sorted = preSorted.sortByKey()

//for( line <- sorted.take(10)) {
//	printf("%s %s\n",line._1,line._2)}

val sorted1 = sc.parallelize(sorted.takeOrdered(10))

val output = sorted1.map(line => line._2)

output.saveAsTextFile("/user/training/problem6/output")

7. sqoop export --connect jdbc:mysql://localhost:3306/loudacre --username training --password training --table oldestactivations --export-dir /user/training/problem6/output --fields-terminated-by '\t'


8. 
 hdfs dfs -mkdir /user/training/problem8
 hdfs dfs -mkdir /user/training/problem8/output
 hdfs dfs -put chatlogs/ /user/training/problem8/output/

9.
 val chatlogDF = sqlContext.load("/user/training/problem8/output/chatlogs/*", "json") 

val chatlogRDD = chatlogDF.rdd

val filtered2 = chatlogRDD.filter(row => row(2).equals("Device")).map(line=> line(1))

val groupbycountRDD = filtered2.map(line => (line, 1)).reduceByKey(_+_)

val reverse = groupbycountRDD.map(line => (line._2, line._1)).sortByKey(ascending=false)
val rake10 = sc.parallelize(reverse.take(10)).persist()

val jsonCreator = rake10.map(line => "{\"agentName\":\""+line._2+"\", \"ctgNum\":\""+line._1+"\" }")

jsonCreator.saveAsTextFile("/user/training/problem9/output")

/*RESULTS
{"agentName":"Rachel Riley", "ctgNum":"987" }
{"agentName":"Gregory Barber", "ctgNum":"956" }
{"agentName":"Renee Sanders", "ctgNum":"947" }
{"agentName":"Carolyn Jones", "ctgNum":"939" }
{"agentName":"Zackary Ostler", "ctgNum":"937" }
{"agentName":"Beverly Battaglia", "ctgNum":"933" }
{"agentName":"Donald Christopher", "ctgNum":"933" }
{"agentName":"Aaron Henderson", "ctgNum":"931" }
{"agentName":"Andrew Murphy", "ctgNum":"928" }
{"agentName":"Edward Floyd", "ctgNum":"927" }

*/

10. 
/* 1. SOLUTION given an .avsc avro file path for altering table, */
ALTER TABLE accounts_avro
 
SET TBLPROPERTIES (
('avro.schema.url'='user/training/problem10/output.avsc');

SELECT * from accounts_avro limit 2;

/*2. SOLUTION  we also can define modification over avro as literal as below.*/


ALTER TABLE accounts_avro SET TBLPROPERTIES (

'avro.schema.literal'='{
  "type" : "record",
  "name" : "sqoop_import_accounts",
  "doc" : "Sqoop import of accounts",
  "fields" : [ {
    "name" : "acct_num",
    "type" : [ "long", "null" ],
    "columnName" : "acct_num",
    "sqlType" : "4"
  }, {
    "name" : "acct_create_dt",
    "type" : [ "long", "null" ],
    "columnName" : "acct_create_dt",
    "sqlType" : "93"
  }, {
    "name" : "acct_close_dt",
    "type" : [ "long", "null" ],
    "columnName" : "acct_close_dt",
    "sqlType" : "93"
  }, {
    "name" : "first_name",
    "type" : [ "string", "null" ],
    "columnName" : "first_name",
    "sqlType" : "12"
  }, {
    "name" : "address",
    "type" : [ "string", "null" ],
    "columnName" : "address",
    "sqlType" : "12"
  }, {
    "name" : "city",
    "type" : [ "string", "null" ],
    "columnName" : "city",
    "sqlType" : "12"
  }, {
    "name" : "state",
    "type" : [ "string", "null" ],
    "columnName" : "state",
    "sqlType" : "12"
  }, {
    "name" : "zipcode",
    "type" : [ "string", "null" ],
    "columnName" : "zipcode",
    "sqlType" : "12"
  }, {
    "name" : "phone_number",
    "type" : [ "string", "null" ],
    "columnName" : "phone_number",
    "sqlType" : "12"
  }, {
    "name" : "created",
    "type" : [ "long", "null" ],
    "columnName" : "created",
    "sqlType" : "93"
  }, {
    "name" : "modified_date",
    "type" : [ "long", "null" ],
    "columnName" : "modified",
    "sqlType" : "93",
     "aliases":["modified"]
  }, {
    "name" : "last_accessed",
    "type" : [ "long", "null" ],
    "columnName" : "modified",
    "sqlType" : "93",
    "default" : 42
  } ],
  "tableName" : "accounts"
}');

11. flume-ng agent --conf /etc/flume-ng/conf --conf-file ~/flume.conf --name agent1 -Dflume.root.logger=INFO,console

sudo mkdir -p /tmp/spooldir
sudo chmod a+w -R /tmp
./copy-move-weblogs.sh /tmp/spooldir/
